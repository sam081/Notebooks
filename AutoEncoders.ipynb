{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom statistics import mean\nfrom itertools import islice\n\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data.dataloader import DataLoader\n\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\nimport torchvision\n\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir('../input/'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# here we will be using Kuzushiji-MNIST dataset which is having 70K images\ntrain_labels = np.load('../input/kmnist-train-labels.npz')['arr_0']\ntest_labels = np.load('../input/kmnist-test-labels.npz')['arr_0']\n\ntrain_images = np.load('../input/kmnist-train-imgs.npz')['arr_0']\ntest_images = np.load('../input/kmnist-test-imgs.npz')['arr_0']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"char_df = pd.read_csv('../input/kmnist_classmap.csv')\nprint(char_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes, count = np.unique(train_labels,return_counts=True)\nprint(classes,'\\n', count)\n# so the dataset is properly balanced among the classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# also lets chech the distribution in the test set.\nnp.unique(test_labels,return_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# find the size of the images\nprint(train_images.shape)\nprint(test_images.shape)\nprint(train_labels.shape)\nprint(test_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets also create a visualisation fucntion\ndef plot_images(images, labels,random=False):\n    if random ==  False:\n        plt.figure(figsize=(12,12))\n        for i in range(10):\n            imgs = images[np.where(labels==i)]\n            lbls = labels[np.where(labels==i)]\n            for j in range(10):\n                plt.subplot(10,10,10*i+j+1)\n                plt.xticks([])\n                plt.yticks([])\n                plt.grid(False)\n                plt.imshow(imgs[j],cmap=plt.cm.binary)\n                plt.xlabel(lbls[j])\n    else:\n        plt.figure(figsize=(12,12))\n        for i in range(10):\n            imgs = images[np.where(labels==i)]\n            lbls = labels[np.where(labels==i)]\n            for j in range(10):\n                plt.subplot(10,10,10*i+j+1)\n                plt.xticks([]);plt.yticks([])\n                plt.grid(False)\n                index = np.random.randint(1, 10)\n                plt.imshow(imgs[index],cmap=plt.cm.binary)\n                plt.xlabel(lbls[index])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_images(train_images,train_labels, random=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot_images(test_images,test_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class KMNIST_Dataset(Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n        \n    def __len__(self):\n        return (len(self.images))\n    \n    def __getitem__(self, index):\n        image = self.images[index].reshape(28,28,1)\n        label = self.labels[index]\n        \n        if self.transform is not None:\n            image = self.transform(image)\n            \n        return image,label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose([transforms.ToTensor()])\ntrain_dataset = KMNIST_Dataset(train_images, train_labels, transform=transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = DataLoader(train_dataset, batch_size=16, shuffle=True)\ntrain_iter = iter(train_gen)\nimages, labels = next(train_iter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(images.size(),labels.size())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = torchvision.utils.make_grid(images)\n\nplt.imshow(grid.numpy().transpose((1, 2, 0)))\nplt.axis('off')\nplt.title(labels.numpy());","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class autoencoder(nn.Module):\n    def __init__(self):\n        super(autoencoder,self).__init__()\n        # encoder \n        self.encoder = nn.Sequential(\n            nn.Conv2d(1, 32, 3, padding=1),  # b x 28 x 28 x 32     \n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2,2),               # b x 14 x 14 x 32\n            nn.Conv2d(32, 16, 3, padding=1), # b x 14 x 14 x 16\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2,2),               # b x 7 x 7 x 16\n            nn.Conv2d(16, 8, 3, padding=1),  # b x 7 x 7 x 8\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2,2)                # b x 3 x 3 x 8\n        )\n        # decoder\n        self.decoder = nn.Sequential(\n            nn.Conv2d(8, 8, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(8, 16, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(16, 32, 3,padding=1),\n            nn.ReLU(inplace=True),\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(32, 1, 3, padding=3),    # padding = 3, was used to make the input and output of same size\n            nn.Sigmoid()\n        )\n        \n        \n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 100\nlr = 0.001","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_img(x):\n    x = 0.5 * (x + 1)\n    x = x.clamp(0, 1)\n    x = x.view(x.size(0), 1, 28, 28)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = autoencoder().cuda()\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=lr,\n                             weight_decay=1e-5)\nlosses = []\nfor epoch in range(epochs):\n    running_loss = 0\n    for img, _ in train_gen:\n        img = img.to('cuda')\n        output = model(img)\n        optimizer.zero_grad()  \n        #print(output.shape,img.shape)\n        loss = criterion(output, img)\n        running_loss += loss.item()\n        #losses.append(loss.item())\n        loss.backward()\n        optimizer.step()\n    \n    print('epoch [{}/{}], loss:{:.4f}'\n          .format(epoch+1, epochs, running_loss/len(train_gen)))\n    losses.append(running_loss/len(train_gen))\n    if epoch % 10 == 0:\n        pic = to_img(output.cpu().data)\n        save_image(pic, 'image_{}.png'.format(epoch))\n\ntorch.save(model.state_dict(), './conv_autoencoder.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(losses)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}